{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aula 14 - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm up\n",
    "\n",
    "![](https://i.imgur.com/j7po4ZB.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectativas\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "![](https://assets.rebelmouse.io/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vbWVkaWEucmJsLm1zL2ltYWdlP3U9JTJGZmlsZXMlMkYyMDE1JTJGMTIlMkYyMCUyRjYzNTg2MjQxNTQ3NjM1Mzk3MC03NDE0Nzc2NzRfdHVtYmxyX2xwZnd6enhPUHQxcXp0d3RlLmdpZiZhbXA7aG89aHR0cCUzQSUyRiUyRmNkbjEudGhlb2R5c3NleW9ubGluZS5jb20mYW1wO3M9OTA0JmFtcDtoPWVlZTI4YmFhOTllZDE0YzFjYTM0YjA2YjAwZGMwYjRlZDllNzNiMjI5MjQ3NzQ3ZTY4N2RiYjg5ZWFlNmNjMGUmYW1wO3NpemU9OTgweCZhbXA7Yz0zNTg0ODI2MDE0IiwiZXhwaXJlc19hdCI6MTU2MDY5MzE4OH0.MQ6bc8mUWAsjqLd2zH53nhFvI3MCuu4mUP4-uyFn43E/img.jpg)\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning Pipeline\n",
    "![Machine Learning Pipeline](https://cdn-images-1.medium.com/max/1600/1*2T5rbjOBGVFdSvtlhCqlNg.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering is an art\n",
    "\n",
    "> \"Each problem is domain specific and better features (suited to the problem) is often the **deciding factor** of the performance of your system.\"\n",
    "> \"Data Scientists often spend 70% of their time in the data preparation phase before modeling.\"               \n",
    "> — [Link 1](https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b) do pré-aula.\n",
    "\n",
    "> “Coming up with features is difficult, time-consuming, requires expert knowledge. ‘Applied machine learning’ is basically feature engineering.\"\n",
    "> — [Prof. Andrew Ng.](https://en.wikipedia.org/wiki/Andrew_Ng) (Stanford)\n",
    "\n",
    "> “Some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used.”  \n",
    "> — [Prof. Pedro Domingos](https://en.wikipedia.org/wiki/Pedro_Domingos) (University of Washington)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================\n",
    "#### Dataset: dados históricos dos funcionários.\n",
    "#### Tarefa: prever promoção do funcionário\n",
    "=============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando o que precisaremos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:21:35.124729Z",
     "start_time": "2019-08-02T23:21:34.764189Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:21:36.049105Z",
     "start_time": "2019-08-02T23:21:36.001232Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Base Analytics.csv')\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrando numericos e excluindo nulos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:21:37.529988Z",
     "start_time": "2019-08-02T23:21:37.504335Z"
    }
   },
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "data = data[data['Admissão'] >= '2011-01-01'].reset_index().drop(columns='index')\n",
    "data_num = data.select_dtypes(include=numerics).copy()\n",
    "data_num = data_num.drop(columns=['ADP', 'Cod.Cargo', 'Cod.Cargo Admissão', 'CC', \n",
    "                                              'Hora Extra 2016', 'Hora Negativa 2016', 'Ad. Noturno 2016', \n",
    "                                              'Absenteísmo 2016', 'Hora Extra 2017', 'Hora Negativa 2017', \n",
    "                                              'Ad. Noturno 2017', 'Absenteísmo 2017', 'Banda', \n",
    "                                              '2012/13 Goal Achievement'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:21:37.918064Z",
     "start_time": "2019-08-02T23:21:37.912944Z"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:21:38.295855Z",
     "start_time": "2019-08-02T23:21:38.287285Z"
    }
   },
   "outputs": [],
   "source": [
    "data_old = data_num.dropna()\n",
    "data_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:22:08.057822Z",
     "start_time": "2019-08-02T23:22:08.044639Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data_old.drop(columns='PROMOVIDO')\n",
    "y = data_old['PROMOVIDO']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:22:08.948150Z",
     "start_time": "2019-08-02T23:22:08.569247Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_confusion_matrix(y_test, y_pred)\n",
    "_ = plot_confusion_matrix(y_test, y_pred, normalize='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E se ao invés de excluir os nulos, substituíssemos pela média?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:22:16.931982Z",
     "start_time": "2019-08-02T23:22:16.894753Z"
    }
   },
   "outputs": [],
   "source": [
    "data_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:22:17.144730Z",
     "start_time": "2019-08-02T23:22:17.137292Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in data_num.columns:\n",
    "    qtt = data_num[col].isnull().sum()\n",
    "    if qtt > 0:\n",
    "        print(col, qtt)\n",
    "        data_num.update(data_num[col].fillna(data_num[col].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:22:17.450734Z",
     "start_time": "2019-08-02T23:22:17.438020Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data_num.drop(columns=['PROMOVIDO'])\n",
    "y = data_num['PROMOVIDO']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:22:18.159454Z",
     "start_time": "2019-08-02T23:22:17.758361Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_confusion_matrix(y_test, y_pred)\n",
    "_ = plot_confusion_matrix(y_test, y_pred, normalize='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Scaler](https://scikit-learn.org/0.19/modules/generated/sklearn.preprocessing.StandardScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:22:24.291573Z",
     "start_time": "2019-08-02T23:22:24.281545Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_num_scaled = pd.DataFrame(scaler.fit_transform(data_num.drop(columns='PROMOVIDO')),\n",
    "                               columns=list(data_num.drop(columns='PROMOVIDO').columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:22:25.457742Z",
     "start_time": "2019-08-02T23:22:25.443950Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data_num_scaled\n",
    "y = data_num['PROMOVIDO']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:22:26.444415Z",
     "start_time": "2019-08-02T23:22:26.118805Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_confusion_matrix(y_test, y_pred)\n",
    "_ = plot_confusion_matrix(y_test, y_pred, normalize='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[RobustScaler](https://scikit-learn.org/0.19/modules/generated/sklearn.preprocessing.RobustScaler.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:22:33.780578Z",
     "start_time": "2019-08-02T23:22:33.769806Z"
    }
   },
   "outputs": [],
   "source": [
    "rscaler = RobustScaler()\n",
    "data_num_rscaled = pd.DataFrame(rscaler.fit_transform(data_num.drop(columns='PROMOVIDO')),\n",
    "                               columns=list(data_num.drop(columns='PROMOVIDO').columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:22:34.099206Z",
     "start_time": "2019-08-02T23:22:34.088362Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data_num_rscaled\n",
    "y = data_num['PROMOVIDO']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:22:34.739997Z",
     "start_time": "2019-08-02T23:22:34.406375Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = plot_confusion_matrix(y_test, y_pred)\n",
    "_ = plot_confusion_matrix(y_test, y_pred, normalize='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarization\n",
    "- Ao invés de um count, por exemplo, usar somente a informação de ter ou não aquela informação.\n",
    "- Exemplo: quantas vezes cada usuário ouviu uma música vs. se ouviu ou não uma música.\n",
    "- No contexto do nosso dataset: se tivéssemos uma coluna que só dissesse quando foi o último aumento do funcionário, poderíamos usar somente a informação se houve aumento ou não."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interaction between features\n",
    "- Além dos valores individuais, podemos extrair informação importante da interação que pode haver entre features.\n",
    "- No contexto nosso dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning\n",
    "- Podem haver valores muito raros, mas próximos de valores mais numerosos; é relevante a informação granular?\n",
    "- Também podemos ter maior interesse em um grupo - ex: público alvo por idade;\n",
    "- No contexto do nosso dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rounding\n",
    "- Mesma ideia do binning\n",
    "- Exemplos?\n",
    "- E no contexto nosso dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Transformation \n",
    "- Log: Log transforms are useful when applied to skewed distributions as they tend to expand the values which fall in the range of lower magnitudes and tend to compress or reduce the values which fall in the range of higher magnitudes.\n",
    "- Box-Cox"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
