{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aula 14 - Feature Engineering - Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:50:06.176619Z",
     "start_time": "2019-08-02T23:50:05.237692Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:50:14.839585Z",
     "start_time": "2019-08-02T23:50:14.818306Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Base Analytics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:50:15.666860Z",
     "start_time": "2019-08-02T23:50:15.642097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filtrando os dados numéricos\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "data = data[data['Admissão'] >= '2011-01-01'].reset_index().drop(columns='index')\n",
    "data_num = data.select_dtypes(include=numerics).copy()\n",
    "data_num = data_num.drop(columns=['ADP', 'Cod.Cargo', 'Cod.Cargo Admissão', 'CC', \n",
    "                                              'Hora Extra 2016', 'Hora Negativa 2016', 'Ad. Noturno 2016', \n",
    "                                              'Absenteísmo 2016', 'Hora Extra 2017', 'Hora Negativa 2017', \n",
    "                                              'Ad. Noturno 2017', 'Absenteísmo 2017', 'Banda', \n",
    "                                              '2012/13 Goal Achievement'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:50:16.114627Z",
     "start_time": "2019-08-02T23:50:16.074971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preenchendo os nulos\n",
    "for col in data_num.columns:\n",
    "    qtt = data_num[col].isnull().sum()\n",
    "    if qtt > 0:\n",
    "        print(col, qtt)\n",
    "        data_num.update(data_num[col].fillna(data_num[col].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:50:16.495980Z",
     "start_time": "2019-08-02T23:50:16.486064Z"
    }
   },
   "outputs": [],
   "source": [
    "# Aplicando o StandardScaler \n",
    "scaler = StandardScaler()\n",
    "data_num_scaled = pd.DataFrame(scaler.fit_transform(data_num.drop(columns='PROMOVIDO')),\n",
    "                               columns=list(data_num.drop(columns='PROMOVIDO').columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quais outras features usar?\n",
    "Quais são os tipos das features desse dataset?\n",
    "\n",
    "Podemos/queremos usar todas elas? \n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:50:17.986841Z",
     "start_time": "2019-08-02T23:50:17.799257Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop(columns=data_old.columns).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:50:18.278013Z",
     "start_time": "2019-08-02T23:50:18.266541Z"
    }
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/one_hot1.png)\n",
    "![](images/one_hot2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:50:19.658736Z",
     "start_time": "2019-08-02T23:50:19.654230Z"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "sex_intlabels = le.fit_transform(data['Sexo'])\n",
    "data['Sexo_'] = sex_intlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:50:19.835093Z",
     "start_time": "2019-08-02T23:50:19.822906Z"
    }
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "sex_cols = ohe.fit_transform(data[['Sexo_']]).toarray()\n",
    "sex_cols_labels = ['Sexo_'+str(cls_label) for cls_label in set(sex_intlabels)]\n",
    "sex_df = pd.DataFrame(sex_cols, columns=sex_cols_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:51:15.590088Z",
     "start_time": "2019-08-02T23:51:15.250362Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = data_num_scaled\n",
    "X = pd.concat([data_num_scaled,sex_df], axis=1)\n",
    "y = data_num['PROMOVIDO']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "_ = plot_confusion_matrix(y_test, y_pred)\n",
    "_ = plot_confusion_matrix(y_test, y_pred, normalize='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummies\n",
    "Pandas Dataframe function [*get_dummies*](http://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:50:38.866018Z",
     "start_time": "2019-08-02T23:50:38.854155Z"
    }
   },
   "outputs": [],
   "source": [
    "sex_dummies = pd.get_dummies(data['Sexo'], drop_first=True)\n",
    "sex_dummies.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:50:39.037645Z",
     "start_time": "2019-08-02T23:50:39.022905Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.concat([data_num_scaled,sex_dummies], axis=1)\n",
    "X.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T23:51:03.206040Z",
     "start_time": "2019-08-02T23:51:02.817088Z"
    }
   },
   "outputs": [],
   "source": [
    "y = data_num['PROMOVIDO']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "_ = plot_confusion_matrix(y_test, y_pred)\n",
    "_ = plot_confusion_matrix(y_test, y_pred, normalize='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect Coding\n",
    "- Bem similar ao *dummy*;\n",
    "- Substitui por -1 todos os 0s que representam uma das categorias (primeira ou última) no dummy encoding;\n",
    "- Exemplo do [link 2](https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63) do pré-aula:\n",
    "\n",
    "![Example1](images/effect_coding.png)\n",
    "\n",
    "- [Outro exemplo](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqwhat-is-effect-coding/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bin-counting \n",
    "- Maldição da dimensionalidade, categorias \"grandes\" (com muitos valores distintos);\n",
    "- Usa probabilidade baseada em informação estatística da relação do valor com o target;\n",
    "- Exemplo simplificado do [link 2](https://towardsdatascience.com/understanding-feature-engineering-part-2-categorical-data-f54324193e63): construir valores de probabilidade de um ataque DDoS ser causado por qualquer um dos endereços IP baseado em **dados históricos** de endereços IP relacionados a ataques DDoS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Hashing Scheme\n",
    "- Maldição da dimensionalidade;\n",
    "- **Função Hash** tipicamente usada com um número pré-definido de features resultantes (vetor de comprimento pré-definido) de forma que os valores de hash dos valores da categoria sejam usados como índices nesse vetor predefinido e os valores sejam atualizados de acordo.\n",
    "- Funções Hash mapeiam uma grande quantidade de valores em uma quantidade finita (e pequena) de valores -> colisões.\n",
    "- [Explicação básica sobre funções hash](https://www.techtudo.com.br/artigos/noticia/2012/07/o-que-e-hash.html)\n",
    "- [Função Scikit Learn](https://scikit-learn.org/0.19/modules/generated/sklearn.feature_extraction.FeatureHasher.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
